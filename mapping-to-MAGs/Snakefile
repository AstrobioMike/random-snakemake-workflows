import os

configfile: "config.yaml"


########################################
############# General Info #############
########################################

"""
See the corresponding 'config.yaml' file for general use information.
Variables that may need to be adjusted should be changed there, not here.
"""

## example usage command ##
# snakemake --use-conda --conda-prefix ${CONDA_PREFIX}/envs -j 2 -p

# `--use-conda` – this specifies to use the conda environments included in the workflow
# `--conda-prefix` – this allows us to point to where the needed conda environments should be stored. Including 
    # this means if we use the workflow on a different dataset somewhere else in the future, it will re-use the same 
    # conda environments rather than make new ones. The value listed here, `${CONDA_PREFIX}/envs`, is the default 
    # location for conda environments (the variable `${CONDA_PREFIX}` will be expanded to the appropriate location 
    # on whichever system it is run on).
# `-j` – this lets us set how many jobs Snakemake should run concurrently (keep in mind that many of the thread 
    # and cpu parameters set in the config.yaml file will be multiplied by this)
# `-p` – specifies to print out each command being run to the screen

# See `snakemake -h` for more options and details.


########################################
#### Reading samples file into list ####
########################################

sample_IDs_file = config["sample_info_file"]
sample_ID_list = [line.strip() for line in open(sample_IDs_file)]

MAG_IDs_file = config["MAG_info_file"]
MAG_ID_list = [line.strip() for line in open(MAG_IDs_file)]

# making sure there are all unique names in both
if len(set(sample_ID_list)) != len(sample_ID_list):

    print("\n    Not all sample IDs in the " + str(config["sample_info_file"]) + " file are unique :(\n")
    print("    Exiting for now.\n")
    exit()

if len(set(MAG_ID_list)) != len(MAG_ID_list):

    print("\n    Not all MAG IDs in the " + str(config["MAG_info_file"]) + " file are unique :(\n")
    print("    Exiting for now.\n")
    exit()


########################################
######## Setting up directories ########
########################################

dirs_to_create = [config["mapping_dir"], config["combined_MAG_mapping_results_dir"], config["logs_dir"], "benchmarks"]

for dir in dirs_to_create:
    try:
        os.mkdir(dir)
    except:
        pass


########################################
############# Rules start ##############
########################################

rule all:
    input:
        config["combined_MAG_mapping_results_dir"] + "Combined-MAG-level-coverages.tsv"

    shell:
        """
        bash scripts/combine-benchmarks.sh
        """



rule combine_all_MAGs_for_bowtie2_index:
    input:
        expand(config["MAGs_dir"] + "{ID}" + config["MAG_suffix"], ID = MAG_ID_list)
    output:
        config["MAGs_dir"] + "All-MAGs.fa"
    shell:
        """
        cat {input} > {output}
        """


rule make_bowtie2_index:
    """
    This rule builds the bowtie2 index and runs the mapping for each sample.
    """
    conda:
        "envs/mapping.yaml"
    input:
        config["MAGs_dir"] + "All-MAGs.fa"
    params:
        index = config["mapping_dir"] + "All-MAGs-index"
    output:
        expand(config["mapping_dir"] + "All-MAGs-index{ext}", ext = [".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2"])
    log:
        config["logs_dir"] + "bowtie2-build.log"
    benchmark:
        "benchmarks/make_bowtie2_index-benchmarks.tsv"
    shell:
        """
        bowtie2-build {input} {params.index} > {log} 2>&1
        """


rule run_mapping:
    """
    This rule runs the mapping for each sample.
    """
    conda:
        "envs/mapping.yaml"
    input:
        index_built_trigger = expand(config["mapping_dir"] + "All-MAGs-index{ext}", ext = [".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2"]),
        R1 = config["reads_dir"] + "{ID}" + config["R1_suffix"],
        R2 = config["reads_dir"] + "{ID}" + config["R2_suffix"]
    params:
        index = config["mapping_dir"] + "All-MAGs-index",
        mapping_info = config["mapping_dir"] + "{ID}-mapping-info.txt",
        num_threads = config["num_threads"]
    resources:
        cpus = config["num_threads"],
        mem_mb = 5000
    output:
        config["mapping_dir"] + "{ID}.bam"
    log:
        config["logs_dir"] + "{ID}-bowtie2-mapping.log"
    benchmark:
        "benchmarks/run_mapping-{ID}-benchmarks.tsv"
    shell:
        """
        bowtie2 --mm -q --threads {params.num_threads} -x {params.index} -1 {input.R1} -2 {input.R2} \
                --no-unal 2> {params.mapping_info} | samtools view -b | samtools sort -@ {params.num_threads} \
                > {output} 2> /dev/null
        """


rule get_cov_and_det:
    """
    This rule pulls out contig-level coverage and detection information for each sample,
    and filters it based on requiring at least 50% detection (coverage set to 0 if not).
    """

    conda:
        "envs/mapping.yaml"
    input:
        bam = config["mapping_dir"] + "{ID}.bam"
    output:
        pileup_contig_cov_and_det = config["mapping_dir"] + "{ID}-pileup-contig-cov-and-det.tsv"
    log:
        config["logs_dir"] + "{ID}-pileup.log"
    benchmark:
        "benchmarks/get_cov_and_det-{ID}-benchmarks.tsv"
    shell:
        """
        pileup.sh -in {input.bam} out={output.pileup_contig_cov_and_det} > {log} 2>&1
        """


rule gen_cov_and_det_tables:
    """
    This rule takes the output from the get_cov_and_det rule above, and makes coverage 
    and detection tables.
    """

    conda:
        "envs/bit.yaml"
    input:
        expand(config["mapping_dir"] + "{ID}-pileup-contig-cov-and-det.tsv", ID = sample_ID_list)
    params:
        sample_IDs_file = config["sample_info_file"],
        MAG_IDs_file = config["MAG_info_file"],
        MAGs_dir = config["MAGs_dir"],
        mapping_dir = config["mapping_dir"],
        output_dir = config["combined_MAG_mapping_results_dir"]
    output:
        config["combined_MAG_mapping_results_dir"] + "Combined-MAG-level-coverages.tsv"
    benchmark:
        "benchmarks/gen_cov_and_det_tables-benchmarks.tsv"
    shell:
        """
        python scripts/gen-MAG-coverage-and-detection-tables.py -s {params.sample_IDs_file} -M {params.MAG_IDs_file} \
                                                                --MAG-directory {params.MAGs_dir} \
                                                                --sample-coverage-info-directory {params.mapping_dir} \
                                                                --output-directory {params.output_dir}
        """
